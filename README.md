K-Means sharded clustering
==========================

Исходная постановка задачи
--------------------------

Необходимо уменьшить размер входных данных с потерей точности, к примеру, снизить число точек с 10 миллионов до 100 
тысяч. Для этого подходят алгоритмы кластеризации, но с одним нюансом: пока не найдено рабочего GPU-решения, 
поддерживающего такие размерности: всё упирается в память видеокарты. 

Предложенное решение
--------------------

Большой набор исходных данных бьется на равные блоки (шардируется). Для каждого блока находится свое решение задачи 
K-Means на GPU. Полученные наборы центроидов объединяются, номера кластеров для входных данных корректируются в 
соответствии с номерами шардов.

Преимущества
------------

* обход проблемы недостатка памяти GPU
* явный "легкий" параллелизм
 
Недостатки
----------

* полученная кластеризация не является оптимальной с т.з. любых метрик
* в результатах могут появлятся идентичные и очень близкие центроиды

Пример использования
--------------------

```sh
$> ./gpu_kmsc --factors 20 --cluster 200 --shard_size 4000 ../samples.bin

```
shard_size - число точек в одном шарде
samples.bin - матрица исходных данных по строкам Nsamples * Ffactors (float32)

Результаты сохраняются в файлы:
* centroids.bin - матрица центроидов по строкам Nclusters * Ffactors (float32)
* assignments.bin - вектор номеров кластеров для исходных данных Nsamples (uint32)

Реализация K-Means
------------------

Использована библиотека [libKMCUDA](https://github.com/src-d/kmcuda).

Разработка и сборка
-------------------

```sh
$> git clone https://github.com/tumb1er/gpu_kmsc.git
$> git submodule init # kmcuda
$> git submodule update
$> cmake \ # набор флагов соответствует libKMCUDA 
    -D DISABLE_PYTHON=y \
    -D DISABLE_R=y      \
    -D CUDA_ARCH=50     \
    -D CUDA_TOOLKIT_ROOT_DIR=/usr/local/cuda-8.0/ \
   .
 
 $> make
```
